  a.  If you use read and  < file, the shell reads the input from
      the file.  That is a good thing.  For example, just yesterday
      I wrote in a shell script:

	ls -t | while read fname
                do
                      ... stuff
		done

      Here, I wanted to read filenames one by one and do something
      with them.  I could have used   

		for f in `ls -t`

      but for directories with LOTS of files, the command line could
      hit its limit.  This flows the data from one process to another
      do there is no limit.

  b.  regarding X=AAAA cmd
      Try this
		$ TZ=PST8PDT date
		$ date
		$ echo $TZ

      the shell will make the assignment for the duration of that
      command.  It is only useful for env variables since they are
      passed to the command.  

      It is a different way of passing args to external programs.
      The usual way is through argv() after the command name.  This
      means you can use named variables and set them before the
      command and the command (i.e. the program) can pick those
      args from the environment.

      The args may not be passed after the command because regular
      commands may have args that contain the '=' char.  


  In the test script, what does  2> mean?  What about $?

  2> filename

  means 'direct fd 2 to filename'  That is, send stderr to filename.

  By writing    cmd > file1 2> file2
  you tell the
  shell to run 'cmd' with stdout attached to file1 and stderr attached
  to file2.  You can put any number in front of the > and tell the
   shelll to attach that fd to that file.  

  For example, if you had a file that split a file into three categories,
  you could have it print the data to fd 4,5, and 6 with

	write(4, buffer, strlen(buffer) )   etc

  and then run the program with

	cmd 4>list1 5>list2 6>list3

  and all the file opening etc would be done by the shell.
  Pretty weird, but really useful in some cases.  

  ALSO

	$? is a special variable that the shell maintains.  It
	is the exit() status of the last process run.

-----------------------------------------------------------------------------

> 1)  Is there a place somewhere that you know of where the workings of 
> the refresh() in curses is described (i.e. source code)?  be interesting 
> to see how it can be done...

The source for curses will show it in detail.  There are several versions
of curses. The original one was done at Berkeley.  A fancier one was
later done at AT&T using barely compatible functions.  An open source
free version was done later and has now taken over the BSD lineage.

The original bsd sources are at:  

    ftp://ftp.uu.net/systems/unix/bsd-sources/lib/libcurses/

and refresh.c.Z is there.  You have to explore the code some to see
how the internal version of the screen is kept and how it knows which
parts to look at.  That earlier code is simpler to follow than the
later, more complicated versions.


> 3)  & more currently - processes are a little hard to get my head 
> around, but if I could ask some quick questions to see if I understand 
> it right -

> A process and the program that resides in it's space are in a sense 2 
> different things, but when an exec* is called, is a new process then 
> created, if not, does it have the same pid as it did before the exec* 
> call or a new one? (I could easily check this out for myself...)

   When a the code in a process calls exec() the kernel runs a new
   program in that process.  The pid stays the same.  It is possible
   for one process to chain a sequence of programs forever assuming
   that each program it ran had an exec() to run the next one.

> Some of the reasons for "cloning" are
> the clone quickly has all the attributes of the parent process (userid, 
> privileges, ...) and, by starting up where the fork occurred, it also 
> has all the environment  information needed to give what's important to 
> new program (process?)  called by exec*?

   I am not sure about the reasons for cloning but the benefits are 
   as you describe.

> fork() is done the way it is to allow a call to exec* without having to 
> lose the parent process but still enables exec* to be called as if there 
> wasn't a fork - that is, without fork() working the way it does, there 
> would have to be a whole different way of setting up an exec* if you 
> wanted to keep the parent around.  Is that a coherent question? I guess 
> I'm trying to understand why fork() works the way it does...

   The question sounds pretty coherent.  Let me start from scratch to
   see if that meets some of your questions.

   Programs sometimes want to run other programs, so an o/s has to provide
   some mechanism for doing that.  One mechanism would be to provide a
   system call named run_program(programname) that would tell the o/s to
   launch the named program.  That would work ok, but there are a few
   questions that come to mind at once.

   a) Should the caller be blocked until the new program ends or should
      the new program go on its way and let the caller go back to its
      work?  If so, the run_program() call would need to take some other
      parameter to tell it whether to block the parent.

      What about setting up file connections or certain priviledges or
      environment variables?  If those had to be set when you called
      run_program() then you'd need more options to the run_program()
      call.  E.g.  run_program("sort", NO_BLOCK, "stdin=/tmp/foo", 
                                priority=x, ... )
      A process can set all sorts of attributes.  If the run_program()
      model were to be maximally flexible, then it would have to allow
      the caller to specify any combination of attributes to apply to
      the new program/process.  

      The advantage of fork() then exec() is that those settings do 
      not need to be duplicated from `set them for me' to `set them
      for my child'. Instead, the same calls that work for `set them
      for me' automatically, through fork and exec,  produce the 
      effects for `set them for the child'.



